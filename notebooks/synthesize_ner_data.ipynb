{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "## Important libs ##\n",
    "import os\n",
    "from pathlib import Path\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "os.chdir(Path.cwd().parent)\n",
    "\n",
    "from src.utils import load_env_file\n",
    "\n",
    "load_env_file()\n",
    "api_key = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "huggingface_hub.login(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning distilBERT (baseline to compare with LLM later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\", trust_remote_code=\"true\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing (tokenization and padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model.dataset_configs import tokenize_ner_models\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_ner_models,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
     ]
    }
   ],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabrieldiasmp\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/language_models/wandb/run-20250826_075900-2q25ya9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/2q25ya9h' target=\"_blank\">curious-energy-8</a></strong> to <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/2q25ya9h' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/2q25ya9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "project_name = \"ner_fine_tuning\"\n",
    "group = \"ner_fine_tuning\"\n",
    "# This will open a window so you can login to W&B.\n",
    "# If that doesn't work, set your W&B API key below\n",
    "# If you do, remove your key before publishing to GitHub.\n",
    "\n",
    "# %env WANDB_API_KEY=YOUR_WANDB_API_KEY\n",
    "#wandb.login()\n",
    "run = wandb.init(project=project_name, group=group, mode=\"online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.dataset_configs import HFTextDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HFTextDataset(tokenized_datasets[\"train\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = HFTextDataset(tokenized_datasets[\"validation\"])\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last_layers_only = True\n",
    "\n",
    "if train_last_layers_only:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from src.model.training import FlexibleLightningModel, HFLightningModel, train_model_lightning\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "lightning_model = FlexibleLightningModel(\n",
    "    model=model, label_name=\"labels\", learning_rate=0.05, num_classes=9, task_type=\"token_classification\")\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"best\")\n",
    "\n",
    "trainer = train_model_lightning(\n",
    "    max_epochs=5,\n",
    "    project_name=project_name,\n",
    "    group=group,\n",
    "    metric_to_monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250823_171706-kxo8muyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">exalted-glade-5</a></strong> to <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                             | Params | Mode \n",
      "---------------------------------------------------------------------------\n",
      "0 | model         | DistilBertForTokenClassification | 66.4 M | eval \n",
      "1 | train_acc     | MulticlassAccuracy               | 0      | train\n",
      "2 | val_acc       | MulticlassAccuracy               | 0      | train\n",
      "3 | test_acc      | MulticlassAccuracy               | 0      | train\n",
      "4 | val_precision | MulticlassPrecision              | 0      | train\n",
      "5 | val_recall    | MulticlassRecall                 | 0      | train\n",
      "6 | val_f1        | MulticlassF1Score                | 0      | train\n",
      "---------------------------------------------------------------------------\n",
      "6.9 K     Trainable params\n",
      "66.4 M    Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.479   Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "95        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0693c0c2e5c4432288e2614009c7e807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee1004ea2364cdb9d6318264213ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c347d089ef489693121d07a5252d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f16bc7dde9458f8967688ee9ebe99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82a04855e374ffe9d95dbf211eb1144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6559e9f8a40e4d34b523d69573a9b10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5082c22317504f1cbbd26eb4446ebbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆██████</td></tr><tr><td>train_acc_epoch</td><td>▁█▁▄▁</td></tr><tr><td>train_acc_step</td><td>▅█▄▄▃▅▅▁▇▄▇▆▃▂▅▆▅▇▅▅▇▆▆▅▇▅▅▃▄▄▆▄▃▆▆▆▅▄▄▅</td></tr><tr><td>train_loss</td><td>▄▁▄▄▄▃▃▇▂▅▁▂▄█▃▂▃▂▅▃▂▂▄▄▂▄▃▄▃▅▂▄▄▂▂▄▃▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▄▁▄█▅</td></tr><tr><td>val_f1_class_0</td><td>▁▂▇█▆</td></tr><tr><td>val_f1_class_1</td><td>▆▁█▇▆</td></tr><tr><td>val_f1_class_2</td><td>▄▇▁█▂</td></tr><tr><td>val_f1_class_3</td><td>▇▁█▆▇</td></tr><tr><td>val_f1_class_4</td><td>█▁▄▄▂</td></tr><tr><td>val_f1_class_5</td><td>█▁▇▆▅</td></tr><tr><td>val_f1_class_6</td><td>█▄▁▆▇</td></tr><tr><td>val_f1_class_7</td><td>▇▆▇█▁</td></tr><tr><td>val_f1_class_8</td><td>▅▅██▁</td></tr><tr><td>val_loss</td><td>▂█▄▁█</td></tr><tr><td>val_precision_class_0</td><td>█▄▂▅▁</td></tr><tr><td>val_precision_class_1</td><td>▁█▆▇▃</td></tr><tr><td>val_precision_class_2</td><td>█▅█▆▁</td></tr><tr><td>val_precision_class_3</td><td>█▆▂▁▆</td></tr><tr><td>val_precision_class_4</td><td>▃▇▁▆█</td></tr><tr><td>val_precision_class_5</td><td>█▁▇▄▃</td></tr><tr><td>val_precision_class_6</td><td>▆▁█▃▅</td></tr><tr><td>val_precision_class_7</td><td>▃▁█▄▅</td></tr><tr><td>val_precision_class_8</td><td>▁▁█▄▃</td></tr><tr><td>val_recall_class_0</td><td>▁▄█▅█</td></tr><tr><td>val_recall_class_1</td><td>█▁▆▅▇</td></tr><tr><td>val_recall_class_2</td><td>▂▇▁▇█</td></tr><tr><td>val_recall_class_3</td><td>▅▁█▇▆</td></tr><tr><td>val_recall_class_4</td><td>█▁█▂▁</td></tr><tr><td>val_recall_class_5</td><td>▁▅▂▇█</td></tr><tr><td>val_recall_class_6</td><td>▅█▁▇▆</td></tr><tr><td>val_recall_class_7</td><td>▇█▄▆▁</td></tr><tr><td>val_recall_class_8</td><td>█▅▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc_epoch</td><td>0.95465</td></tr><tr><td>train_acc_step</td><td>0.95607</td></tr><tr><td>train_loss</td><td>0.22556</td></tr><tr><td>trainer/global_step</td><td>2194</td></tr><tr><td>val_acc</td><td>0.95382</td></tr><tr><td>val_f1_class_0</td><td>0.98665</td></tr><tr><td>val_f1_class_1</td><td>0.78969</td></tr><tr><td>val_f1_class_2</td><td>0.77767</td></tr><tr><td>val_f1_class_3</td><td>0.64182</td></tr><tr><td>val_f1_class_4</td><td>0.51136</td></tr><tr><td>val_f1_class_5</td><td>0.82213</td></tr><tr><td>val_f1_class_6</td><td>0.64948</td></tr><tr><td>val_f1_class_7</td><td>0.51477</td></tr><tr><td>val_f1_class_8</td><td>0.36295</td></tr><tr><td>val_loss</td><td>0.32482</td></tr><tr><td>val_precision_class_0</td><td>0.97947</td></tr><tr><td>val_precision_class_1</td><td>0.77839</td></tr><tr><td>val_precision_class_2</td><td>0.72752</td></tr><tr><td>val_precision_class_3</td><td>0.72005</td></tr><tr><td>val_precision_class_4</td><td>0.7416</td></tr><tr><td>val_precision_class_5</td><td>0.7575</td></tr><tr><td>val_precision_class_6</td><td>0.68178</td></tr><tr><td>val_precision_class_7</td><td>0.7411</td></tr><tr><td>val_precision_class_8</td><td>0.45179</td></tr><tr><td>val_recall_class_0</td><td>0.99411</td></tr><tr><td>val_recall_class_1</td><td>0.82281</td></tr><tr><td>val_recall_class_2</td><td>0.87313</td></tr><tr><td>val_recall_class_3</td><td>0.61203</td></tr><tr><td>val_recall_class_4</td><td>0.42198</td></tr><tr><td>val_recall_class_5</td><td>0.92943</td></tr><tr><td>val_recall_class_6</td><td>0.65936</td></tr><tr><td>val_recall_class_7</td><td>0.42702</td></tr><tr><td>val_recall_class_8</td><td>0.35827</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-glade-5</strong> at: <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl</a><br> View project at: <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250823_171706-kxo8muyl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = HFTextDataset(tokenized_datasets[\"test\"])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gabrieldiasmp/ner_fine_tuning/model-8hc1yf5k:best'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{wandb.run.entity}/{project_name}/model-{wandb.run.id}:best\"\n",
    "\n",
    "\"model-nc4fzygv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-olprujj3:best, 253.28MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.4 (178.0MB/s)\n"
     ]
    }
   ],
   "source": [
    "# Define checkpoint reference.\n",
    "checkpoint_reference = f\"{wandb.run.entity}/{project_name}/model-{'olprujj3'}:best\" # wandb.run.id\n",
    "\n",
    "# Download checkpoint locally (if not already cached).\n",
    "artifact = run.use_artifact(checkpoint_reference, type=\"model\")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LightningModule with checkpoint\n",
    "model_test = FlexibleLightningModel.load_from_checkpoint(\n",
    "    checkpoint_path=str(artifact_dir) + \"/model.ckpt\",\n",
    "    model=model,\n",
    "    learning_rate=0.05,\n",
    "    num_classes=9,\n",
    "    label_name=\"labels\",\n",
    "    task_type=\"token_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `predict_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c55157a27564346b916fca5ab1f7a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_labels = batch_outputs = trainer.predict(model=model_test, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logits', 'preds', 'labels'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2249e+01, -9.4911e+00, -1.6683e+01, -9.9180e-01, -7.2359e+00,\n",
       "          1.5641e+00, -9.3560e-03, -2.9993e+00,  2.7563e+00],\n",
       "        [ 3.8110e+00, -1.7084e+01, -2.9783e+01,  1.8779e+01,  1.5866e-01,\n",
       "          5.4683e+00, -1.1140e+01,  5.0917e+00, -9.5163e+00],\n",
       "        [-3.9796e+00, -5.7436e+01, -1.2956e+01, -2.7093e+00,  1.9136e+01,\n",
       "         -1.9439e+01,  2.1610e+00, -1.9562e+01,  1.1541e+01],\n",
       "        [ 3.3517e-01, -4.3263e+01, -1.5210e+01, -3.5497e+00,  1.4251e+01,\n",
       "         -8.7733e+00,  1.9600e+00, -1.6918e+01,  4.3850e+00],\n",
       "        [ 1.2856e+01, -3.3975e+01, -2.1374e+01,  1.3754e+00,  4.7026e+00,\n",
       "         -6.5030e+00, -1.0460e+01, -9.6904e+00,  3.8632e-01],\n",
       "        [ 1.2301e+01, -2.6842e+01, -1.4833e+01,  1.4773e-02,  3.9869e+00,\n",
       "         -1.3567e+01, -9.3527e+00, -1.1409e+01,  4.0558e+00],\n",
       "        [ 2.7036e+01, -2.1116e+01, -1.3880e+01, -2.7127e+00, -4.1150e+00,\n",
       "         -1.1620e+01, -1.8338e+01, -1.1250e+01, -2.0302e-02],\n",
       "        [ 1.6786e+01, -1.3735e+01, -1.8715e+01,  2.3163e+00, -8.6016e+00,\n",
       "          2.9781e+00, -8.9769e+00,  2.0185e+00, -1.4424e+01],\n",
       "        [ 1.9379e+01, -1.9437e+01, -1.3099e+01, -5.4004e+00, -4.9754e+00,\n",
       "         -6.6612e+00, -1.2089e+01, -2.7734e+00, -5.7051e+00],\n",
       "        [ 1.3488e+01, -2.3604e+01, -1.7027e+01,  3.5419e+00, -1.3886e+00,\n",
       "          3.9899e+00, -7.2674e+00, -1.4419e+01, -1.1858e+01],\n",
       "        [ 1.9228e+01, -1.9681e+01, -3.0732e+00, -1.2857e+01, -5.1772e+00,\n",
       "         -1.3047e+01, -8.8012e+00, -1.1888e+01,  1.1914e+00],\n",
       "        [ 1.7075e+00,  1.3323e+01,  6.2730e+00,  2.6019e+00, -1.0238e+01,\n",
       "         -3.3332e+00, -1.3608e+01, -1.6506e+00, -5.6874e+00],\n",
       "        [-6.0665e+00, -1.2894e-02,  1.1358e+01,  4.9331e-01, -6.5695e+00,\n",
       "          4.3124e+00, -6.3236e+00, -8.2285e+00, -1.1854e+00],\n",
       "        [ 2.0119e+01, -1.3911e+01, -9.5184e+00, -6.5754e+00, -8.6802e+00,\n",
       "         -1.0129e+01, -2.0200e+01, -9.3410e-01,  4.6477e+00],\n",
       "        [ 2.5136e+01, -6.6656e+00, -9.7900e+00, -1.1391e+01, -9.5633e+00,\n",
       "         -6.7506e+00, -1.4213e+01, -2.7860e+00, -2.3437e+00],\n",
       "        [-3.7644e-01, -9.3220e+00, -1.4640e+01,  5.9150e+00, -6.9534e+00,\n",
       "          1.6506e+01,  4.4737e-01, -6.2914e-01, -8.0738e+00],\n",
       "        [ 1.9381e+01, -2.8734e+01, -1.6249e+01, -7.1740e+00, -1.3105e+00,\n",
       "         -9.5950e+00, -6.7394e+00, -1.2655e+01,  2.9311e+00],\n",
       "        [ 1.5418e+01, -1.7309e+01, -1.6014e+01, -8.8781e+00,  3.7675e-01,\n",
       "         -2.1515e+00, -1.5012e+00, -1.3573e+01, -2.6105e+00],\n",
       "        [ 1.6265e+01, -1.4898e+01, -1.4425e+01, -8.4060e+00, -3.7697e-01,\n",
       "         -1.3672e+01,  2.0107e-01, -9.3008e+00, -1.5594e+00],\n",
       "        [ 1.9474e+01, -7.2007e+00, -1.8223e+01, -3.7991e+00, -1.2923e+01,\n",
       "         -3.9397e+00, -1.3884e+01,  8.3962e+00, -1.6649e+00],\n",
       "        [ 1.0632e+01, -5.8646e+00, -4.4581e+00, -8.2843e+00, -5.2674e+00,\n",
       "         -3.1746e+00, -3.7800e+00,  2.9913e-01, -4.6453e+00],\n",
       "        [ 1.5876e+01, -1.9141e+01, -1.2344e+01, -9.7928e-03, -1.9557e+00,\n",
       "         -1.2091e+01, -1.7068e+00, -8.9602e+00, -4.4203e+00],\n",
       "        [ 1.7650e+01, -1.3848e+01, -1.4754e+01, -8.5559e+00,  1.9365e+00,\n",
       "         -1.2128e+01, -6.5211e+00, -5.7224e+00, -5.6708e+00],\n",
       "        [ 1.5472e+01, -1.3571e+01, -1.0171e+01, -3.0258e+00, -5.3827e-01,\n",
       "         -1.1097e+01, -5.6729e+00, -5.9548e+00, -4.9195e+00],\n",
       "        [ 1.9673e+01, -1.8704e+01, -1.6129e+01, -9.5973e+00, -2.4088e+00,\n",
       "         -1.0009e+01, -1.4697e+01, -2.7200e+00,  1.5471e+00],\n",
       "        [ 1.6282e+01, -1.1910e+01, -1.3489e+01, -1.9794e+00, -3.5381e+00,\n",
       "         -1.2301e+01, -1.7577e+00, -8.9882e+00, -5.0601e+00],\n",
       "        [ 1.8214e+01, -5.6633e+00, -1.5339e+01, -1.0779e+00, -6.6372e+00,\n",
       "         -6.0110e+00, -1.0237e+01, -7.5039e+00, -3.3627e+00],\n",
       "        [ 2.1374e+00,  8.4438e-01, -1.1924e+01,  6.0871e+00, -6.7148e+00,\n",
       "          3.4942e+00, -1.5881e+01, -8.0726e-01, -6.2355e+00],\n",
       "        [-2.3069e+00, -1.5657e+01,  3.0921e+00, -5.2905e+00,  7.1289e+00,\n",
       "         -7.8333e+00, -2.1778e+00, -1.3581e+01, -2.1890e+00],\n",
       "        [ 1.1960e+01, -3.9197e+01, -1.0671e+01, -4.1255e+00, -5.9589e-01,\n",
       "         -8.5287e+00,  2.6417e+00, -1.0142e+01, -3.6327e+00],\n",
       "        [ 7.9654e+00, -3.9601e+01, -1.1125e+01, -4.8718e+00, -8.9072e-01,\n",
       "         -9.6857e+00,  3.9890e+00, -6.6054e+00,  4.7260e-01],\n",
       "        [ 9.2426e+00, -7.0497e+00, -1.4198e+01,  4.2649e+00, -2.9624e+00,\n",
       "          7.4139e+00, -7.8220e+00,  1.9300e-01, -6.4457e+00],\n",
       "        [ 8.5391e+00, -7.4115e+00, -1.4436e+01,  4.5280e+00, -2.4302e+00,\n",
       "          8.6465e+00, -7.0994e+00, -2.1292e+00, -6.5192e+00],\n",
       "        [ 1.4091e+01, -1.0987e+01, -1.6538e+01,  4.2400e+00, -4.4943e+00,\n",
       "          2.7603e+00, -8.4629e+00,  2.8601e+00, -5.2294e+00],\n",
       "        [ 1.0209e+01, -8.3848e+00, -1.0718e+01,  1.4705e+00, -4.5150e+00,\n",
       "          7.6222e+00, -7.4756e+00, -2.0015e+00, -4.8505e+00],\n",
       "        [ 1.1628e+01, -6.3139e+00, -1.4989e+01,  2.5058e+00, -2.8805e-01,\n",
       "          2.4030e+00, -8.7356e+00, -4.7327e+00, -3.0213e+00],\n",
       "        [ 1.6067e+01, -6.4120e+00, -1.3051e+01, -8.1520e-01, -8.3246e+00,\n",
       "          4.6711e+00, -7.2741e+00,  4.3371e+00, -7.8611e+00],\n",
       "        [ 1.4660e+01, -8.7258e+00, -1.1497e+01, -2.2086e+00, -7.2919e+00,\n",
       "          3.4757e+00, -6.0782e+00,  3.6436e+00, -6.5086e+00],\n",
       "        [ 1.3281e+01, -6.1806e+00, -6.6047e+00, -3.3244e+00, -5.6453e+00,\n",
       "          8.5125e-01, -6.5623e+00,  1.8860e+00, -6.4253e+00],\n",
       "        [ 8.4879e+00, -2.1038e+00, -1.5648e+00, -2.5432e+00, -2.7416e+00,\n",
       "         -6.4052e-01, -8.4392e+00,  8.6872e-02, -4.7183e+00],\n",
       "        [ 1.0526e+01, -5.9601e+00, -4.5051e+00, -2.8548e+00, -2.1549e+00,\n",
       "          1.1896e+00, -7.9719e+00, -2.5294e+00, -3.8393e+00],\n",
       "        [ 7.5516e+00,  8.0491e-02,  2.2827e+00, -1.8319e+00, -2.4434e+00,\n",
       "         -4.8053e+00, -8.9691e+00,  1.6801e-01, -5.0225e+00],\n",
       "        [ 8.5997e+00, -5.0690e+00, -6.8064e+00,  3.2574e-02, -2.5724e+00,\n",
       "          3.4821e+00, -7.2373e+00, -1.8502e+00, -4.1391e+00]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs[0]['logits'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_ner(batch_outputs, label_names):\n",
    "    \"\"\"\n",
    "    Compute token-level NER metrics (precision, recall, F1) from a list of batch outputs.\n",
    "\n",
    "    Args:\n",
    "        batch_outputs (list of dicts): Each dict must contain keys:\n",
    "            - 'logits': [batch, seq_len, num_classes] tensor\n",
    "            - 'labels': [batch, seq_len] tensor (optional, can be None)\n",
    "        label_names (list of str): Maps class indices to string labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Metrics including F1, precision, recall and classification report (if labels exist)\n",
    "        list: all_preds (list of lists of string labels)\n",
    "        list: all_labels (list of lists of string labels, empty if labels not provided)\n",
    "    \"\"\"\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for out in batch_outputs:\n",
    "        logits = out[\"logits\"]\n",
    "        labels = out.get(\"labels\", None)\n",
    "\n",
    "        # Token-level predicted class indices\n",
    "        preds = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "        if labels is not None:\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            for p, l in zip(preds, labels):\n",
    "                valid_preds = [label_names[pi] for pi, li in zip(p, l) if li != -100]\n",
    "                valid_labels = [label_names[li] for pi, li in zip(p, l) if li != -100]\n",
    "                all_preds.append(valid_preds)\n",
    "                all_labels.append(valid_labels)\n",
    "        else:\n",
    "            for p in preds:\n",
    "                all_preds.append([label_names[pi] for pi in p])\n",
    "\n",
    "    metrics = {}\n",
    "    if all_labels:\n",
    "        metrics[\"f1\"] = f1_score(all_labels, all_preds)\n",
    "        metrics[\"precision\"] = precision_score(all_labels, all_preds)\n",
    "        metrics[\"recall\"] = recall_score(all_labels, all_preds)\n",
    "        metrics[\"classification_report\"] = classification_report(all_labels, all_preds)\n",
    "    else:\n",
    "        metrics[\"message\"] = \"No labels available. Only predictions returned.\"\n",
    "\n",
    "    return metrics, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model with few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6712658430932135\n",
      "Precision: 0.6136696978586096\n",
      "Recall: 0.7407932011331445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.70      0.79      0.74      1668\n",
      "        MISC       0.43      0.58      0.50       702\n",
      "         ORG       0.50      0.67      0.57      1661\n",
      "         PER       0.76      0.84      0.80      1617\n",
      "\n",
      "   micro avg       0.61      0.74      0.67      5648\n",
      "   macro avg       0.60      0.72      0.65      5648\n",
      "weighted avg       0.62      0.74      0.68      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics, all_preds, all_labels = evaluate_ner(batch_outputs, label_names)\n",
    "\n",
    "if \"classification_report\" in metrics:\n",
    "    print(\"F1:\", metrics[\"f1\"])\n",
    "    print(\"Precision:\", metrics[\"precision\"])\n",
    "    print(\"Recall:\", metrics[\"recall\"])\n",
    "    print(metrics[\"classification_report\"])\n",
    "else:\n",
    "    print(metrics[\"message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model fine-tuned with 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6473708846933999\n",
      "Precision: 0.5786610878661088\n",
      "Recall: 0.7345963172804533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.66      0.85      0.74      1668\n",
      "        MISC       0.37      0.63      0.47       702\n",
      "         ORG       0.50      0.61      0.55      1661\n",
      "         PER       0.71      0.79      0.75      1617\n",
      "\n",
      "   micro avg       0.58      0.73      0.65      5648\n",
      "   macro avg       0.56      0.72      0.63      5648\n",
      "weighted avg       0.59      0.73      0.65      5648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics, all_preds, all_labels = evaluate_ner(batch_outputs, label_names)\n",
    "\n",
    "if \"classification_report\" in metrics:\n",
    "    print(\"F1:\", metrics[\"f1\"])\n",
    "    print(\"Precision:\", metrics[\"precision\"])\n",
    "    print(\"Recall:\", metrics[\"recall\"])\n",
    "    print(metrics[\"classification_report\"])\n",
    "else:\n",
    "    print(metrics[\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '115',\n",
       " 'tokens': ['New', 'Zealand', 'innings'],\n",
       " 'pos_tags': [22, 22, 21],\n",
       " 'chunk_tags': [11, 12, 12],\n",
       " 'ner_tags': [5, 6, 0]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['test'][115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 9])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_outputs[0]['logits'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LLMs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
