{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important libs ##\n",
    "import os\n",
    "from pathlib import Path\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "os.chdir(Path.cwd().parent)\n",
    "\n",
    "from src.utils import load_env_file\n",
    "\n",
    "load_env_file()\n",
    "api_key = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "huggingface_hub.login(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning distilBERT (baseline to compare with LLM later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"conll2003\", trust_remote_code=\"true\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model.dataset_configs import tokenize_ner_models\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_ner_models,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
     ]
    }
   ],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-PER': 1,\n",
       " 'I-PER': 2,\n",
       " 'B-ORG': 3,\n",
       " 'I-ORG': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-LOC': 6,\n",
       " 'B-MISC': 7,\n",
       " 'I-MISC': 8}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/language_models/wandb/run-20250823_165844-nc4fzygv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/nc4fzygv' target=\"_blank\">colorful-armadillo-4</a></strong> to <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/nc4fzygv' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/nc4fzygv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "project_name = \"ner_fine_tuning\"\n",
    "group = \"ner_fine_tuning\"\n",
    "# This will open a window so you can login to W&B.\n",
    "# If that doesn't work, set your W&B API key below\n",
    "# If you do, remove your key before publishing to GitHub.\n",
    "\n",
    "# %env WANDB_API_KEY=YOUR_WANDB_API_KEY\n",
    "#wandb.login()\n",
    "run = wandb.init(project=project_name, group=group, mode=\"online\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.dataset_configs import HFTextDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HFTextDataset(tokenized_datasets[\"train\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = HFTextDataset(tokenized_datasets[\"validation\"])\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last_layers_only = True\n",
    "\n",
    "if train_last_layers_only:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from src.model.training import FlexibleLightningModel, HFLightningModel, train_model_lightning\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "lightning_model = FlexibleLightningModel(\n",
    "    model=model, label_name=\"labels\", learning_rate=0.05, num_classes=9, task_type=\"token_classification\")\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"best\")\n",
    "\n",
    "trainer = train_model_lightning(\n",
    "    max_epochs=5,\n",
    "    project_name=project_name,\n",
    "    group=group,\n",
    "    metric_to_monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250823_171706-kxo8muyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">exalted-glade-5</a></strong> to <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                             | Params | Mode \n",
      "---------------------------------------------------------------------------\n",
      "0 | model         | DistilBertForTokenClassification | 66.4 M | eval \n",
      "1 | train_acc     | MulticlassAccuracy               | 0      | train\n",
      "2 | val_acc       | MulticlassAccuracy               | 0      | train\n",
      "3 | test_acc      | MulticlassAccuracy               | 0      | train\n",
      "4 | val_precision | MulticlassPrecision              | 0      | train\n",
      "5 | val_recall    | MulticlassRecall                 | 0      | train\n",
      "6 | val_f1        | MulticlassF1Score                | 0      | train\n",
      "---------------------------------------------------------------------------\n",
      "6.9 K     Trainable params\n",
      "66.4 M    Non-trainable params\n",
      "66.4 M    Total params\n",
      "265.479   Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "95        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0693c0c2e5c4432288e2614009c7e807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee1004ea2364cdb9d6318264213ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c347d089ef489693121d07a5252d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f16bc7dde9458f8967688ee9ebe99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82a04855e374ffe9d95dbf211eb1144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6559e9f8a40e4d34b523d69573a9b10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5082c22317504f1cbbd26eb4446ebbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆██████</td></tr><tr><td>train_acc_epoch</td><td>▁█▁▄▁</td></tr><tr><td>train_acc_step</td><td>▅█▄▄▃▅▅▁▇▄▇▆▃▂▅▆▅▇▅▅▇▆▆▅▇▅▅▃▄▄▆▄▃▆▆▆▅▄▄▅</td></tr><tr><td>train_loss</td><td>▄▁▄▄▄▃▃▇▂▅▁▂▄█▃▂▃▂▅▃▂▂▄▄▂▄▃▄▃▅▂▄▄▂▂▄▃▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▄▁▄█▅</td></tr><tr><td>val_f1_class_0</td><td>▁▂▇█▆</td></tr><tr><td>val_f1_class_1</td><td>▆▁█▇▆</td></tr><tr><td>val_f1_class_2</td><td>▄▇▁█▂</td></tr><tr><td>val_f1_class_3</td><td>▇▁█▆▇</td></tr><tr><td>val_f1_class_4</td><td>█▁▄▄▂</td></tr><tr><td>val_f1_class_5</td><td>█▁▇▆▅</td></tr><tr><td>val_f1_class_6</td><td>█▄▁▆▇</td></tr><tr><td>val_f1_class_7</td><td>▇▆▇█▁</td></tr><tr><td>val_f1_class_8</td><td>▅▅██▁</td></tr><tr><td>val_loss</td><td>▂█▄▁█</td></tr><tr><td>val_precision_class_0</td><td>█▄▂▅▁</td></tr><tr><td>val_precision_class_1</td><td>▁█▆▇▃</td></tr><tr><td>val_precision_class_2</td><td>█▅█▆▁</td></tr><tr><td>val_precision_class_3</td><td>█▆▂▁▆</td></tr><tr><td>val_precision_class_4</td><td>▃▇▁▆█</td></tr><tr><td>val_precision_class_5</td><td>█▁▇▄▃</td></tr><tr><td>val_precision_class_6</td><td>▆▁█▃▅</td></tr><tr><td>val_precision_class_7</td><td>▃▁█▄▅</td></tr><tr><td>val_precision_class_8</td><td>▁▁█▄▃</td></tr><tr><td>val_recall_class_0</td><td>▁▄█▅█</td></tr><tr><td>val_recall_class_1</td><td>█▁▆▅▇</td></tr><tr><td>val_recall_class_2</td><td>▂▇▁▇█</td></tr><tr><td>val_recall_class_3</td><td>▅▁█▇▆</td></tr><tr><td>val_recall_class_4</td><td>█▁█▂▁</td></tr><tr><td>val_recall_class_5</td><td>▁▅▂▇█</td></tr><tr><td>val_recall_class_6</td><td>▅█▁▇▆</td></tr><tr><td>val_recall_class_7</td><td>▇█▄▆▁</td></tr><tr><td>val_recall_class_8</td><td>█▅▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc_epoch</td><td>0.95465</td></tr><tr><td>train_acc_step</td><td>0.95607</td></tr><tr><td>train_loss</td><td>0.22556</td></tr><tr><td>trainer/global_step</td><td>2194</td></tr><tr><td>val_acc</td><td>0.95382</td></tr><tr><td>val_f1_class_0</td><td>0.98665</td></tr><tr><td>val_f1_class_1</td><td>0.78969</td></tr><tr><td>val_f1_class_2</td><td>0.77767</td></tr><tr><td>val_f1_class_3</td><td>0.64182</td></tr><tr><td>val_f1_class_4</td><td>0.51136</td></tr><tr><td>val_f1_class_5</td><td>0.82213</td></tr><tr><td>val_f1_class_6</td><td>0.64948</td></tr><tr><td>val_f1_class_7</td><td>0.51477</td></tr><tr><td>val_f1_class_8</td><td>0.36295</td></tr><tr><td>val_loss</td><td>0.32482</td></tr><tr><td>val_precision_class_0</td><td>0.97947</td></tr><tr><td>val_precision_class_1</td><td>0.77839</td></tr><tr><td>val_precision_class_2</td><td>0.72752</td></tr><tr><td>val_precision_class_3</td><td>0.72005</td></tr><tr><td>val_precision_class_4</td><td>0.7416</td></tr><tr><td>val_precision_class_5</td><td>0.7575</td></tr><tr><td>val_precision_class_6</td><td>0.68178</td></tr><tr><td>val_precision_class_7</td><td>0.7411</td></tr><tr><td>val_precision_class_8</td><td>0.45179</td></tr><tr><td>val_recall_class_0</td><td>0.99411</td></tr><tr><td>val_recall_class_1</td><td>0.82281</td></tr><tr><td>val_recall_class_2</td><td>0.87313</td></tr><tr><td>val_recall_class_3</td><td>0.61203</td></tr><tr><td>val_recall_class_4</td><td>0.42198</td></tr><tr><td>val_recall_class_5</td><td>0.92943</td></tr><tr><td>val_recall_class_6</td><td>0.65936</td></tr><tr><td>val_recall_class_7</td><td>0.42702</td></tr><tr><td>val_recall_class_8</td><td>0.35827</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-glade-5</strong> at: <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning/runs/kxo8muyl</a><br> View project at: <a href='https://wandb.ai/gabrieldiasmp/ner_fine_tuning' target=\"_blank\">https://wandb.ai/gabrieldiasmp/ner_fine_tuning</a><br>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250823_171706-kxo8muyl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DatasetDict(\n",
    "    {\n",
    "        \"test\": dataset.select(range(0, 300))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_tokenized = tokenize_hugging_face(test_dataset, model_str=\"distilbert-base-uncased\")\n",
    "\n",
    "test_dataset_tokenized.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "\n",
    "#test_ds = HFTextDataset(test_dataset_tokenized)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset_tokenized['test'],\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gabrieldiasmp/llm_annotation_ft/model-l0zsmva2:best'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{wandb.run.entity}/{project_name}/model-{wandb.run.id}:best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-l0zsmva2:best, 255.52MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.1 (239.5MB/s)\n"
     ]
    }
   ],
   "source": [
    "# Define checkpoint reference.\n",
    "checkpoint_reference = f\"{wandb.run.entity}/{project_name}/model-{wandb.run.id}:best\"\n",
    "\n",
    "# Download checkpoint locally (if not already cached).\n",
    "artifact = run.use_artifact(checkpoint_reference, type=\"model\")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint.\n",
    "model = HFLightningModel.load_from_checkpoint(str(artifact_dir) + \"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade023c15bd44bc4afabe65b67015b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predicted_labels = batch_outputs = trainer.predict(model=model, dataloaders=test_loader)\n",
    "logits = torch.cat([batch_output[\"logits\"] for batch_output in batch_outputs])\n",
    "predicted_labels = torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7666666666666667,\n",
       "  'recall': 0.42592592592592593,\n",
       "  'f1-score': 0.5476190476190477,\n",
       "  'support': 54.0},\n",
       " '1': {'precision': 0.84375,\n",
       "  'recall': 0.9529411764705882,\n",
       "  'f1-score': 0.8950276243093923,\n",
       "  'support': 170.0},\n",
       " '2': {'precision': 0.5769230769230769,\n",
       "  'recall': 0.5921052631578947,\n",
       "  'f1-score': 0.5844155844155844,\n",
       "  'support': 76.0},\n",
       " 'accuracy': 0.7666666666666667,\n",
       " 'macro avg': {'precision': 0.7291132478632477,\n",
       "  'recall': 0.6569907885181362,\n",
       "  'f1-score': 0.6756874187813414,\n",
       "  'support': 300.0},\n",
       " 'weighted avg': {'precision': 0.7622788461538461,\n",
       "  'recall': 0.7666666666666667,\n",
       "  'f1-score': 0.7538056970653656,\n",
       "  'support': 300.0}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(test_dataset['test']['label'], predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LLMs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
